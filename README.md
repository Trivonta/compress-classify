# compress-classify


В данном репозитории представлены скрипты для проверки метода классификации на основе компрессии, применённого к статьям из CyberLeninka и arXiv

для Linux/macOS после клонирования, убедитесь, что Linux-бинар 7z убедитесь имеет права на исполнение
chmod +x tools/7zip/7z

Вначале запустите скрипт для загрузки библиотек: Install.py

CyberLeninka
Затем запустите скрипт DownloaderCyberLeninka.py, который скачивает статьи. 
Для остановки загрузки просто останвите работу программы. Для тестирования минимальной работоспособности рекомендуется скачать ~120 стаетй.
После запустите Sup.py. Он отделит часть статей для формирования ядра.
Затем CoreCreater.py. Он сформирует ядро.
Далее предлагается запустить Classification.py. Он попытается классифицировать статьи из Articless. (результат ожидается не очень хорошим так как статей вы скорее всего загрузили мало)
Результат можно посмотреть в classification2.log.
Далее для проверки работоспоспособности оптимизации предлагается еще несколько раз запустить Sup.py. Теперь в Articless2 находятся статьи кандидаты.
Теперь запустите DebugCores.py. Он "продебажит" худшее ядро. Для маленького количества статей не стоит надеятся на существенное улучшение работы, но чтобы протестировать на большом количестве данных нужно много времени.
Логи можно посмотреть в classification.log.


arXiv
Запустите скрипт DownloaderArxiv.py. Он скачивает PDF-статьи с arXiv. Результат — папка Articless_pdf, внутри неё подпапки по темам, в которых лежат .pdf-файлы.
Запустите скрипт totxt.py. Скрипт конвертирует скачанные PDF в текст. Берёт все .pdf из Articless_pdf, Извлекает содержимое и сохраняет в .txt, Разбивает результаты на папки в папке Articless по темам.
После запустите Sup.py. Он отделит часть статей из папки Articless в папку Articless2 для формирования ядра.

Затем запустите CoreCreater.py. Он сформирует ядра(тематические архивы) из тем в папке Articless2. Результат папка Cores с архивами для каждой темы.
Для опимизации состава ядра вместо обычного формирования ядра запустите скрипт updateCore.py. Выполнение скрипта может занять много времени при большом колличестве статей. Результат папка Cores с архивами для каждой темы.

Далее предлагается запустить Classification.py. Он попытается классифицировать статьи из Articless. Результат можно посмотреть в classification2.log.

python Install.py
python DownloaderArxiv.py
python totxt.py
python Sup.py
python CoreCreater.py или python updateCore.py
python Classification.py

